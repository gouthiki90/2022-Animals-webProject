## 크롤링 웨이팅

1. 브라우저가 a페이지 달라고 했을 때
2. 서버 사이드 렌더링으로 다 그려서 주면
3. 브라우저에 그림이 다 완성될 것
4. 해당 페이지를 자바의 버퍼로 읽을 수도 있는데
5. SSR인 경우에는 데이터가 다 담긴다
6. 하지만 CSR인 경우에는 페이지 달라고 했을 때 순수하고 껍데기밖에 없는 a페이지를 준다.
7. 다 그려지는 게 아니라 틀만 준다.
8. 내부적으로 자바스크립트가 발생해서 fetch 요청으로 다시 CSR로 그림을 그린다.



## 웨이트로 크롤링하는 방식

1. 요청하고 5초 있다가 웨이트하고 다운 받으면 모두 다운 받을 수 있다.



## 개발자 도구를 통해서 다운 받는 방식

1. 크롬 개발자 도구에서 네트워크 들어가서 해당 페이지의 쿼리스트링 JSON 파일에 들어감
2. fetch로 하는 페이지가 더 크롤링하기 쉽다. 파싱하기에 쉽기 때문이다.
3. Jsoup 라이브러리 - html 파싱함 
4. 사용법은 공식 문서에서



## HttpHeader

1. Referer 해당 페이지에 들어가기 전에 갔던 사이트 흔적이 있다.
2. 해당 주소 이외의 레퍼러는 요청 불가하게 설정 가능하다. 크롤링 같은 것.
3. /search.naver** 요청했을 때
4. 필터나 인터셉터로 일정 헤더일 때 필터 돌리게 하고 아니면 chain하게 함
5. 이건 자바에서 header를 바꿔넣기만 하면 됨
6. postman에서 할 수도 있는 것임
7. 컴퓨터로 요청하면 블락 먹는데 MAC 번호로 블락시키기 때문에 그물째로 블락시키지 않음
8. User-agent에서 브라우저로 요청한게 아니면 블락 시킬 수도 있음
9. 그럴 때도 header에서 set하면 된다.
10. html을 받는 것은 서버 부하가 심하기 때문에 API로 제공하는 것

